{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIvggdSGA4so"
      },
      "outputs": [],
      "source": [
        "# Importing Requried libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as FT\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from dataset import VOCDataset\n",
        "from utils import non_max_suppression,cellboxes_to_boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cvubI-T7CBK3"
      },
      "outputs": [],
      "source": [
        "#YOLO-V1 Neural Network\n",
        "class Yolov1(nn.Module):\n",
        "    def __init__(self, in_channels=3, split_size=7, num_boxes=2, num_classes=20):\n",
        "        super(Yolov1, self).__init__()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3),\n",
        "            # nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2,2)),\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1),\n",
        "            # nn.BatchNorm2d(192),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2,2)),\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(192, 128, kernel_size=1),\n",
        "            # nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(256, 256, kernel_size=1),\n",
        "            # nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2,2)),\n",
        "\n",
        "            # Block 4\n",
        "            nn.Conv2d(512, 256, kernel_size=1),\n",
        "            # nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(512, 256, kernel_size=1),\n",
        "            # nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(512, 256, kernel_size=1),\n",
        "            # nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(512, 256, kernel_size=1),\n",
        "            # nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=1),\n",
        "            # nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(512, 1024, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2,2)),\n",
        "\n",
        "            # Block 5\n",
        "            nn.Conv2d(1024, 512, kernel_size=1),\n",
        "            # nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(512, 1024, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(1024, 512, kernel_size=1),\n",
        "            # nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(512, 1024, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.1),\n",
        "\n",
        "            nn.Conv2d(1024, 1024, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(1024, 1024, kernel_size=3, stride=2, padding=1),\n",
        "            # nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.1),\n",
        "\n",
        "            # Block 6\n",
        "            nn.Conv2d(1024, 1024, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Conv2d(1024, 1024, kernel_size=3, padding=1),\n",
        "            # nn.BatchNorm2d(1024),\n",
        "            nn.LeakyReLU(0.1),\n",
        "\n",
        "            # Block 7\n",
        "            nn.Flatten(),         #flatten into 1D tensor\n",
        "            nn.Linear(1024 * split_size**2, 400),\n",
        "            nn.Dropout(0.0),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(400, split_size**2 * (num_classes + num_boxes*5))   #a linear layer which predicts the class probabilities and bounding boxes for each grid cell.\n",
        "        )\n",
        "      \n",
        "    def forward(self, x):\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sn_1WFgpCMCf"
      },
      "outputs": [],
      "source": [
        "mse = nn.MSELoss(reduction='sum') #mean squared error loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss: Coordinates of boxes\n",
        "def loss_coord(pred, target, exists_box, better_box):\n",
        "    pred = exists_box * (better_box * pred[..., 26:28] + (1-better_box) * pred[..., 21:23])\n",
        "    target = exists_box * target[..., 21:23]\n",
        "    return mse(pred, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss: Size of boxes\n",
        "def loss_size(pred, target, exists_box, better_box):\n",
        "    pred = exists_box * (better_box * pred[..., 28:30] + (1-better_box) * pred[..., 23:25])\n",
        "    target = exists_box * target[..., 23:25]\n",
        "    pred = torch.sign(pred) * torch.sqrt(torch.abs(pred) + 1e-6)\n",
        "    target = torch.sqrt(target)\n",
        "    return mse(pred, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss function: Prob of not containing object(Penalize both bounding boxes)\n",
        "def loss_no_object(pred, target, exists_box, better_box):\n",
        "    pred1 = (1-exists_box) * pred[..., 20:21]\n",
        "    pred2 = (1-exists_box) * pred[..., 25:26]\n",
        "    target = (1-exists_box) * target[..., 20:21]\n",
        "    return mse(pred1, target) + mse(pred2, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss: Prob of each class\n",
        "def loss_class(pred, target, exists_box, better_box):\n",
        "    pred = exists_box * pred[..., :20]\n",
        "    target = exists_box * target[..., :20]\n",
        "    return mse(pred, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class YoloLoss(nn.Module):\n",
        "    def __init__(self, split_size=7, num_boxes=2, num_classes=20):\n",
        "        super(YoloLoss, self).__init__()\n",
        "        self.split = split_size\n",
        "        self.boxes = num_boxes\n",
        "        self.classes = num_classes\n",
        "        self.lambda_coord = 5\n",
        "        self.lambda_noobj = 0.5\n",
        "    # Target -> ground truth; pred -> prdicted output \n",
        "    def forward(self, pred, target):\n",
        "        pred = pred.reshape(-1, self.split, self.split, self.classes + self.boxes * 5)\n",
        "        better_box = find_better_box(pred, target)\n",
        "        exists_box = target[..., 20:21]\n",
        "        coord_loss = loss_coord(pred, target, exists_box, better_box) # the loss for the bounding box coordinates\n",
        "        size_loss = loss_size(pred, target, exists_box, better_box)   # the loss for the size of the selected box\n",
        "        object_loss = loss_object(pred, target, exists_box, better_box) # the loss for the probability that an object exists in the cell\n",
        "        no_object_loss = loss_no_object(pred, target, exists_box, better_box)\n",
        "        class_loss = loss_class(pred, target, exists_box, better_box)   #the loss for the predicted probability distribution over object classes\n",
        "        loss = self.lambda_coord * (coord_loss + size_loss) + object_loss + self.lambda_noobj * no_object_loss + class_loss\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Input a tensor of bounding boxes(x, y, w, h) and returns four tensors - left x, right x, top y, and bottom y coordinates of the boxes.\n",
        "def get_margin_box(box):\n",
        "    mid_x = box[..., 0:1]\n",
        "    mid_y = box[..., 1:2]\n",
        "    half_width = box[..., 2:3] / 2\n",
        "    half_height = box[..., 3:4] / 2\n",
        "    left_x = mid_x - half_width\n",
        "    right_x = mid_x + half_width\n",
        "    top_y = mid_y - half_height\n",
        "    bot_y = mid_y + half_height\n",
        "    return left_x, right_x, top_y, bot_y\n",
        "\n",
        "# computes the IoU metric between the two boxes\n",
        "def IoU(left_x1, right_x1, top_y1, bot_y1, left_x2, right_x2, top_y2, bot_y2):\n",
        "    left_x_inte = torch.max(left_x1, left_x2)\n",
        "    right_x_inte = torch.min(right_x1, right_x2)\n",
        "    top_y_inte = torch.max(top_y1, top_y2)\n",
        "    bot_y_inte = torch.min(bot_y1, bot_y2)\n",
        "    intersection = (right_x_inte - left_x_inte).clamp(0) * (bot_y_inte - top_y_inte).clamp(0)\n",
        "    box1_area = abs((right_x1 - left_x1) * (bot_y1 - top_y1))\n",
        "    box2_area = abs((right_x2 - left_x2) * (bot_y2 - top_y2))\n",
        "    union = box1_area + box2_area - intersection + 1e-6\n",
        "    return intersection/union\n",
        "    \n",
        "# find better box based on iou metric\n",
        "def find_better_box(pred, target):\n",
        "    left_x1, right_x1, top_y1, bot_y1 = get_margin_box(pred[..., 21:25])\n",
        "    left_x2, right_x2, top_y2, bot_y2 = get_margin_box(pred[..., 26:30])\n",
        "    left_x_target, right_x_target, top_y_target, bot_y_target = get_margin_box(target[..., 21:25])\n",
        "    \n",
        "    iou1 = IoU(left_x1, right_x1, top_y1, bot_y1, left_x_target, right_x_target, top_y_target, bot_y_target)\n",
        "    iou2 = IoU(left_x2, right_x2, top_y2, bot_y2, left_x_target, right_x_target, top_y_target, bot_y_target)\n",
        "    ious = torch.cat([iou1.unsqueeze(3), iou2.unsqueeze(3)], dim=3)\n",
        "    return torch.argmax(ious, dim=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# takes in a list of transformations and applies them to both the input image and the target.\n",
        "class JointCompose(object):\n",
        "    def __init__(self, transforms):\n",
        "        self.transforms = transforms\n",
        "    def __call__(self, img, target):\n",
        "        for t in self.transforms:\n",
        "            img, target = t(img), target\n",
        "        return img, target\n",
        "    \n",
        "transform = JointCompose([transforms.Resize((448, 448)), transforms.ToTensor(),])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train function\n",
        "# DEVICE = \"cpu\"\n",
        "DEVICE = \"cuda\"  # Can switch to GPU by simply uncomment this line\n",
        "\n",
        "def train(dataloader, model, optimizer, loss_fn):\n",
        "    sum_loss = 0\n",
        "    pbar = tqdm(dataloader, leave = False)\n",
        "    for batch, (x, y) in enumerate(pbar):\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        pred = model(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "        sum_loss += loss.item()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return sum_loss / (batch+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test function\n",
        "def test(dataloader, model, optimizer, loss_fn):\n",
        "    sum_loss = 0\n",
        "    pbar = tqdm(dataloader, leave = False)\n",
        "    with torch.no_grad():\n",
        "        for batch, (x, y) in enumerate(pbar):\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            pred = model(x)\n",
        "            loss = loss_fn(pred, y)\n",
        "            sum_loss += loss.item()\n",
        "    return sum_loss / (batch+1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Develop a function to plot the bounding box, predicted label and predicted probability\n",
        "LABEL = [\"airplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"dining table\",\n",
        "\"dog\", \"horse\", \"motorbike\", \"person\", \"potted plant\", \"sheep\", \"sofa\", \"train\", \"TV monitor\"]\n",
        "LABEL_COLOR = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', \n",
        "               '#7f7f7f', '#bcbd22', '#17becf', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', \n",
        "               '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
        "\n",
        "def plot_image(image, boxes, ax):\n",
        "    im = np.array(image)\n",
        "    height, width, _ = im.shape\n",
        "    ax.imshow(im)\n",
        "\n",
        "    for box in boxes:\n",
        "        obj = int(box[0])\n",
        "        prob = box[1]\n",
        "        prob = max(0, min(1, prob))\n",
        "\n",
        "        topleft_x = box[2] - box[4] / 2\n",
        "        topleft_y = box[3] - box[5] / 2\n",
        "        rect = patches.Rectangle(\n",
        "            (topleft_x * width, topleft_y * height),\n",
        "            box[4] * width,\n",
        "            box[5] * height,\n",
        "            linewidth=2,\n",
        "            edgecolor=LABEL_COLOR[obj],\n",
        "            facecolor=\"none\",\n",
        "        )\n",
        "        ax.annotate('{}: {:.2f}'.format(LABEL[obj], prob), \n",
        "                    (topleft_x * width+5, topleft_y * height-10), \n",
        "                    backgroundcolor=LABEL_COLOR[obj])\n",
        "        ax.add_patch(rect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# upload kaggle.json file for allowing program to access kaggle\n",
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!kaggle datasets download -d aladdinpersson/pascal-voc-dataset-used-in-yolov3-video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!unzip pascal-voc-dataset-used-in-yolov3-video.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed = 684\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "LEARNING_RATE = 2e-5\n",
        "BATCH_SIZE = 16 # 64 in original paper\n",
        "WEIGHT_DECAY = 0.0005\n",
        "EPOCHS = 20\n",
        "IMG_DIR = \"PASCAL_VOC/images\"\n",
        "LABEL_DIR = \"PASCAL_VOC/labels\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "small_train_dataset = VOCDataset(\"PASCAL_VOC/1examples.csv\", transform=transform,img_dir=IMG_DIR,label_dir=LABEL_DIR)\n",
        "large_train_dataset = VOCDataset(\"PASCAL_VOC/train.csv\", transform=transform,img_dir=IMG_DIR,label_dir=LABEL_DIR)\n",
        "test_dataset = VOCDataset(\"PASCAL_VOC/test.csv\", transform=transform, img_dir=IMG_DIR, label_dir=LABEL_DIR)\n",
        "\n",
        "small_train_loader = DataLoader(dataset=small_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "large_train_loader = DataLoader(dataset=large_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Create overfit_model and train it on the single image dataset.\n",
        "%matplotlib notebook\n",
        "\n",
        "overfit_model = Yolov1(split_size=7, num_boxes=2, num_classes=20).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(overfit_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "loss_fn = YoloLoss()\n",
        "\n",
        "overfit_loss = []\n",
        "pbar = tqdm(range(EPOCHS))\n",
        "for epoch in pbar:\n",
        "    loss = train(small_train_loader, overfit_model, optimizer, loss_fn)\n",
        "    overfit_loss.append(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pbar = tqdm(range(1))\n",
        "for epoch in pbar:\n",
        "    overfit_loss_test = test(test_loader, overfit_model, optimizer, loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "plt.plot(overfit_loss, label=\"train\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Yolo Loss\")\n",
        "plt.title(\"Loss in Overfit model\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"The loss in training set is {:.2f} while the loss in test set is {:.2f}\".format(overfit_loss[-1], overfit_loss_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(14,10))\n",
        "for x, y in small_train_loader:\n",
        "    for i in range(1):\n",
        "        ax1 = fig.add_subplot(2,2,1)\n",
        "        plt.title(\"Ground truth\")\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        bboxes = cellboxes_to_boxes(y)\n",
        "        bboxes = non_max_suppression(bboxes[i], iou_threshold=0.5, threshold=0.4, box_format=\"midpoint\")\n",
        "        plot_image(x[i].permute(1,2,0).to(\"cpu\"), bboxes, ax1)\n",
        "        \n",
        "        ax2 = fig.add_subplot(2,2,2)\n",
        "        plt.title(\"Overfit prediction(for its training image)\")\n",
        "        bboxes = cellboxes_to_boxes(overfit_model(x))\n",
        "        bboxes = non_max_suppression(bboxes[i], iou_threshold=0.5, threshold=0.4, box_format=\"midpoint\")\n",
        "        plot_image(x[i].permute(1,2,0).to(\"cpu\"), bboxes, ax2)\n",
        "\n",
        "    pred = overfit_model(x)\n",
        "    loss = loss_fn(pred, y)\n",
        "    ax2.text(10, 30, 'Yolo Loss: {:.5f}'.format(loss.item()), fontsize=20, color='white')\n",
        "    break\n",
        "\n",
        "for x, y in test_loader:\n",
        "    for i in range(1):\n",
        "        ax3 = fig.add_subplot(2,2,3)\n",
        "        plt.title(\"Ground truth\")\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        bboxes = cellboxes_to_boxes(y)\n",
        "        bboxes = non_max_suppression(bboxes[i], iou_threshold=0.5, threshold=0.4, box_format=\"midpoint\")\n",
        "        plot_image(x[i].permute(1,2,0).to(\"cpu\"), bboxes, ax3)\n",
        "        ax4 = fig.add_subplot(2,2,4)\n",
        "        plt.title(\"Overfit prediction(for image it has not seen)\")\n",
        "        bboxes = cellboxes_to_boxes(overfit_model(x))\n",
        "        bboxes = non_max_suppression(bboxes[i], iou_threshold=0.5, threshold=0.4, box_format=\"midpoint\")\n",
        "        plot_image(x[i].permute(1,2,0).to(\"cpu\"), bboxes, ax4)\n",
        "    pred = overfit_model(x)\n",
        "    loss = loss_fn(pred, y)\n",
        "    ax4.text(10, 30, 'Yolo Loss: {:.5f}'.format(loss.item()), fontsize=20, color='white')\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib notebook\n",
        "\n",
        "EPOCHS = 10\n",
        "trained_model = Yolov1(split_size=7, num_boxes=2, num_classes=20).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(trained_model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "loss_fn = YoloLoss()\n",
        "trained_loss = []\n",
        "pbar = tqdm(range(EPOCHS))\n",
        "for epoch in pbar:\n",
        "    loss = train(large_train_loader, trained_model, optimizer, loss_fn)\n",
        "    trained_loss.append(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pbar = tqdm(range(1))\n",
        "for epoch in pbar:\n",
        "    trained_loss_test = test(test_loader, trained_model, optimizer, loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "plt.plot(trained_loss, label=\"train\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Yolo Loss\")\n",
        "plt.title(\"Loss in Trained model\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
